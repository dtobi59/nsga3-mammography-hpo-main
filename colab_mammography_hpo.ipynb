{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dtobi59/nsga3-mammography-hpo-main/blob/master/colab_mammography_hpo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm7yOn4vYBHI"
   },
   "source": [
    "# NSGA-III Hyperparameter Optimization for Mammography Classification\n",
    "\n",
    "Multi-objective hyperparameter optimization for deep learning models in breast cancer detection.\n",
    "\n",
    "**Objectives:**\n",
    "- Maximize: Sensitivity, Specificity, AUC\n",
    "- Minimize: Model Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTcHyJsoYBHP"
   },
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "12NCzzMfYBHQ",
    "outputId": "7785c549-c982-4e1f-9e99-f6038eaad0dc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Dec 19 02:12:11 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   58C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk14iyqnYBHR"
   },
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3gDhfYcWYBHS",
    "outputId": "67af64b8-ce51-4a3e-ee47-173b70f9593e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4tBjxL0YBHS"
   },
   "source": [
    "## 3. Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V1HPiuMdYBHT",
    "outputId": "62d7e3ff-e734-431a-8280-b294e81298ca",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'nsga3-mammography-hpo-main'...\n",
      "remote: Enumerating objects: 43, done.\u001b[K\n",
      "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 43 (delta 17), reused 39 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (43/43), 50.58 KiB | 12.64 MiB/s, done.\n",
      "Resolving deltas: 100% (17/17), done.\n",
      "/content/nsga3-mammography-hpo-main\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/dtobi59/nsga3-mammography-hpo-main.git\n",
    "%cd nsga3-mammography-hpo-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1iNi6AA8YBHT",
    "outputId": "bbb61d55-ce21-4f67-bd51-84f5c89c63ad",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uq50P9UvYBHU"
   },
   "source": [
    "## 4. Configure Dataset Path\n",
    "\n",
    "Update the path below to point to your dataset on Google Drive.\n",
    "\n",
    "**Supported datasets:**\n",
    "- `vindr` - VinDr-Mammo\n",
    "- `inbreast` - INbreast\n",
    "\n",
    "**Expected structure:**\n",
    "\n",
    "**VinDr-Mammo:**\n",
    "```\n",
    "vindr-mammo/\n",
    "├── images/\n",
    "│   └── {study_id}/\n",
    "│       └── {image_id}.dicom\n",
    "└── metadata/\n",
    "    └── breast-level_annotations.csv\n",
    "```\n",
    "\n",
    "**INbreast:**\n",
    "```\n",
    "inbreast/\n",
    "└── INbreast Release 1.0/\n",
    "    ├── AllDICOMs/\n",
    "    │   └── {id}_{hash}_MG_{L/R}_{CC/MLO}_ANON.dcm\n",
    "    └── INbreast.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "de89Qc3qYBHV"
   },
   "outputs": [],
   "source": [
    "# Configure your dataset\n",
    "DATASET_NAME = \"vindr\"  # or \"inbreast\"\n",
    "DATA_ROOT = \"/content/drive/MyDrive/vindr-mammo\"  # Update this path!\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/nsga3_outputs\"  # Where to save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_lDx9UyYBHV"
   },
   "source": [
    "## 5. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01Vf7PTnYBHV",
    "outputId": "0cf3809b-7a05-4946-98a6-b6288eae92b6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading vindr dataset from /content/drive/MyDrive/vindr-mammo...\n",
      "VinDr-Mammo: /content/drive/MyDrive/vindr-mammo\n",
      "  Loaded 20000 rows from CSV\n",
      "  BI-RADS distribution in downloaded images:\n",
      "    BI-RADS 1: 13406\n",
      "    BI-RADS 2: 4676\n",
      "    BI-RADS 3: 930\n",
      "    BI-RADS 4: 762\n",
      "    BI-RADS 5: 226\n",
      "  After BI-RADS filter: 19070 (Benign: 18082, Malignant: 988)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Scanning:  89%|████████▉ | 16937/19070 [05:00<01:14, 28.54it/s]"
     ]
    }
   ],
   "source": [
    "from dataset import prepare_dataset\n",
    "\n",
    "print(f\"Loading {DATASET_NAME} dataset from {DATA_ROOT}...\")\n",
    "\n",
    "train_paths, train_labels, val_paths, val_labels = prepare_dataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    data_root=DATA_ROOT\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Train samples: {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n",
    "print(f\"Train labels distribution: {sum(train_labels)} malignant, {len(train_labels) - sum(train_labels)} benign\")\n",
    "print(f\"Val labels distribution: {sum(val_labels)} malignant, {len(val_labels) - sum(val_labels)} benign\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom dataset import load_dicom_image\n\ndef visualize_samples(image_paths, labels, dataset_name, n_samples=6):\n    \"\"\"\n    Visualize sample mammography images.\n\n    Args:\n        image_paths: List of image file paths\n        labels: List of labels (0=benign, 1=malignant)\n        dataset_name: Name for the plot title (e.g., 'Training', 'Validation')\n        n_samples: Number of samples to display\n    \"\"\"\n    # Select random samples\n    n_samples = min(n_samples, len(image_paths))\n    indices = np.random.choice(len(image_paths), n_samples, replace=False)\n\n    # Create subplot grid\n    n_cols = 3\n    n_rows = (n_samples + n_cols - 1) // n_cols\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n\n    if n_rows == 1:\n        axes = axes.reshape(1, -1)\n\n    fig.suptitle(f'{dataset_name} Dataset Samples', fontsize=16, fontweight='bold')\n\n    for idx, ax_idx in enumerate(range(n_samples)):\n        row = ax_idx // n_cols\n        col = ax_idx % n_cols\n        ax = axes[row, col]\n\n        sample_idx = indices[idx]\n        img_path = image_paths[sample_idx]\n        label = labels[sample_idx]\n\n        try:\n            # Load DICOM image\n            image = load_dicom_image(img_path, apply_clahe=True)\n\n            # Display\n            ax.imshow(image, cmap='gray')\n            label_text = 'MALIGNANT' if label == 1 else 'BENIGN'\n            label_color = 'red' if label == 1 else 'green'\n            ax.set_title(f'{label_text}', fontsize=12, fontweight='bold', color=label_color)\n            ax.axis('off')\n\n            # Add filename as subtitle\n            filename = os.path.basename(img_path)\n            ax.text(0.5, -0.05, filename[:30] + '...' if len(filename) > 30 else filename,\n                   ha='center', va='top', transform=ax.transAxes,\n                   fontsize=8, style='italic')\n\n        except Exception as e:\n            ax.text(0.5, 0.5, f'Error loading image:\\n{str(e)[:50]}',\n                   ha='center', va='center', transform=ax.transAxes)\n            ax.axis('off')\n\n    # Hide extra subplots\n    for idx in range(n_samples, n_rows * n_cols):\n        row = idx // n_cols\n        col = idx % n_cols\n        axes[row, col].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Visualize training samples\nprint(\"=\" * 70)\nprint(\"TRAINING SET SAMPLES\")\nprint(\"=\" * 70)\nvisualize_samples(train_paths, train_labels, 'Training', n_samples=6)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"VALIDATION SET SAMPLES\")\nprint(\"=\" * 70)\nvisualize_samples(val_paths, val_labels, 'Validation', n_samples=6)",
   "metadata": {
    "id": "hwApDqYLYBHW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.5 Visualize Sample Images\n",
    "\n",
    "Let's look at some sample mammography images from the training and validation sets."
   ],
   "metadata": {
    "id": "ZrjXh4kjYBHX"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-giixQVYBHX"
   },
   "source": [
    "## 6. Configure Optimization\n",
    "\n",
    "Adjust these parameters based on your computational budget:\n",
    "- **pop_size**: Population size (more = better exploration, longer runtime)\n",
    "- **n_generations**: Number of generations (more = better convergence)\n",
    "- **epochs**: Training epochs per evaluation (reduce for faster testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nSiS81OYBHX"
   },
   "outputs": [],
   "source": [
    "from config import ExperimentConfig\n",
    "from dataclasses import asdict\n",
    "\n",
    "# Load default config\n",
    "config = ExperimentConfig()\n",
    "\n",
    "# Customize NSGA-III parameters\n",
    "config.nsga3.pop_size = 20        # Recommended: 20-50 for quick runs, 100+ for thorough search\n",
    "config.nsga3.n_generations = 10   # Recommended: 5-10 for testing, 20-50 for production\n",
    "\n",
    "# Training epochs per evaluation (reduce for faster testing)\n",
    "TRAINING_EPOCHS = 5  # Recommended: 5 for testing, 10-20 for production\n",
    "\n",
    "print(f\"Optimization Configuration:\")\n",
    "print(f\"  Population size: {config.nsga3.pop_size}\")\n",
    "print(f\"  Generations: {config.nsga3.n_generations}\")\n",
    "print(f\"  Epochs per evaluation: {TRAINING_EPOCHS}\")\n",
    "print(f\"  Total evaluations: ~{config.nsga3.pop_size * config.nsga3.n_generations}\")\n",
    "print(f\"\\nSearching hyperparameters:\")\n",
    "\n",
    "# Convert dataclass to dictionary for iteration\n",
    "hp_space_dict = asdict(config.hyperparameter_space)\n",
    "for param, values in hp_space_dict.items():\n",
    "    print(f\"  {param}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRSBBlMaYBHY"
   },
   "source": [
    "## 7. Create Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p30w4TwBYBHY"
   },
   "outputs": [],
   "source": [
    "from training import full_evaluation\n",
    "\n",
    "def make_eval_fn(tp, tl, vp, vl, epochs=5):\n",
    "    \"\"\"\n",
    "    Creates an evaluation function for the optimizer.\n",
    "\n",
    "    Args:\n",
    "        tp: Training paths\n",
    "        tl: Training labels\n",
    "        vp: Validation paths\n",
    "        vl: Validation labels\n",
    "        epochs: Number of training epochs\n",
    "\n",
    "    Returns:\n",
    "        Evaluation function that takes hyperparameter config and returns objectives\n",
    "    \"\"\"\n",
    "    def eval_fn(hp_config):\n",
    "        hp_config = hp_config.copy()\n",
    "        hp_config['epochs'] = epochs\n",
    "        return full_evaluation(\n",
    "            hp_config,\n",
    "            tp, tl, vp, vl,\n",
    "            device='cuda',  # Use GPU\n",
    "            verbose=True\n",
    "        )\n",
    "    return eval_fn\n",
    "\n",
    "eval_function = make_eval_fn(\n",
    "    train_paths, train_labels,\n",
    "    val_paths, val_labels,\n",
    "    epochs=TRAINING_EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Evaluation function created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSVgKw4MYBHY"
   },
   "source": [
    "## 8. Run Optimization\n",
    "\n",
    "This will take some time depending on your configuration.\n",
    "\n",
    "**Estimated runtime:**\n",
    "- Small (pop=20, gen=5, epochs=5): ~30-60 minutes\n",
    "- Medium (pop=50, gen=10, epochs=10): ~2-4 hours\n",
    "- Large (pop=100, gen=20, epochs=20): ~8-12 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvY2E73yYBHY"
   },
   "outputs": [],
   "source": [
    "from optimization import run_optimization\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "# Change this value (e.g., 42, 123, 456) for different runs\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(f\"Starting optimization with seed={RANDOM_SEED}...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = run_optimization(\n",
    "    hp_space=config.hyperparameter_space,\n",
    "    nsga_config=config.nsga3,\n",
    "    eval_function=eval_function,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    seed=RANDOM_SEED  # Set seed here\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Optimization completed in {elapsed_time/3600:.2f} hours\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sKXfsuSYBHY"
   },
   "source": [
    "## 9. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W466XfWSYBHZ"
   },
   "outputs": [],
   "source": [
    "# Display Pareto front solutions\n",
    "print(f\"\\nFound {len(results['pareto_configs'])} Pareto-optimal solutions\\n\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for i, (cfg, obj) in enumerate(zip(results['pareto_configs'], results['pareto_F'])):\n",
    "    print(f\"\\nSolution {i+1}:\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    # Architecture details\n",
    "    print(f\"  Architecture:\")\n",
    "    print(f\"    Backbone: {cfg['backbone']}\")\n",
    "    print(f\"    Unfreeze: {cfg['unfreeze_strategy']}\")\n",
    "    print(f\"    Dropout: {cfg['dropout_rate']:.2f}\")\n",
    "    print(f\"    FC Hidden: {cfg['fc_hidden_size']}\")\n",
    "\n",
    "    # Training details\n",
    "    print(f\"  Training:\")\n",
    "    print(f\"    Optimizer: {cfg['optimizer']}\")\n",
    "    print(f\"    Learning Rate: {cfg['learning_rate']:.6f}\")\n",
    "    print(f\"    Batch Size: {cfg['batch_size']}\")\n",
    "    print(f\"    Loss: {cfg['loss_function']}\")\n",
    "    if cfg['loss_function'] == 'focal':\n",
    "        print(f\"    Focal Gamma: {cfg.get('focal_gamma', 2.0):.2f}\")\n",
    "\n",
    "    # Augmentation\n",
    "    print(f\"  Augmentation:\")\n",
    "    print(f\"    Horizontal Flip: {cfg['horizontal_flip']}\")\n",
    "    print(f\"    Rotation: {cfg['rotation_range']:.1f}°\")\n",
    "    print(f\"    Mixup: {cfg['use_mixup']}\")\n",
    "\n",
    "    # Performance metrics\n",
    "    print(f\"  Performance:\")\n",
    "    print(f\"    Sensitivity: {obj[0]:.4f}\")\n",
    "    print(f\"    Specificity: {obj[1]:.4f}\")\n",
    "    print(f\"    AUC: {obj[2]:.4f}\")\n",
    "    print(f\"    Model Size: {obj[3]:.2f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTkFVuHgYBHZ"
   },
   "source": [
    "## 10. Visualize Pareto Front (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hULRRqgYBHZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract objectives\n",
    "pareto_F = np.array(results['pareto_F'])\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Pareto Front - Trade-off Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Sensitivity vs Specificity\n",
    "axes[0, 0].scatter(pareto_F[:, 0], pareto_F[:, 1], c='blue', s=100, alpha=0.6)\n",
    "axes[0, 0].set_xlabel('Sensitivity', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Specificity', fontsize=12)\n",
    "axes[0, 0].set_title('Sensitivity vs Specificity')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AUC vs Model Size\n",
    "axes[0, 1].scatter(pareto_F[:, 2], pareto_F[:, 3], c='green', s=100, alpha=0.6)\n",
    "axes[0, 1].set_xlabel('AUC', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Model Size (M params)', fontsize=12)\n",
    "axes[0, 1].set_title('AUC vs Model Size')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Sensitivity vs Model Size\n",
    "axes[1, 0].scatter(pareto_F[:, 0], pareto_F[:, 3], c='purple', s=100, alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Sensitivity', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Model Size (M params)', fontsize=12)\n",
    "axes[1, 0].set_title('Sensitivity vs Model Size')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Overall metrics distribution\n",
    "metrics = ['Sensitivity', 'Specificity', 'AUC', 'Size (M)']\n",
    "avg_values = pareto_F.mean(axis=0)\n",
    "axes[1, 1].bar(metrics, avg_values, color=['blue', 'green', 'red', 'purple'], alpha=0.6)\n",
    "axes[1, 1].set_ylabel('Average Value', fontsize=12)\n",
    "axes[1, 1].set_title('Average Objective Values')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/pareto_front_visualization.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVisualization saved to {OUTPUT_DIR}/pareto_front_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjKBNdCnYBHa"
   },
   "source": [
    "## 11. Save Best Configuration for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLd4po89YBHa"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Find solution with best AUC\n",
    "best_auc_idx = np.argmax(pareto_F[:, 2])\n",
    "best_auc_config = results['pareto_configs'][best_auc_idx]\n",
    "best_auc_objectives = pareto_F[best_auc_idx]\n",
    "\n",
    "print(f\"Best AUC Configuration:\")\n",
    "print(f\"  AUC: {best_auc_objectives[2]:.4f}\")\n",
    "print(f\"  Sensitivity: {best_auc_objectives[0]:.4f}\")\n",
    "print(f\"  Specificity: {best_auc_objectives[1]:.4f}\")\n",
    "print(f\"\\nConfiguration: {json.dumps(best_auc_config, indent=2)}\")\n",
    "\n",
    "# Save to file\n",
    "with open(f\"{OUTPUT_DIR}/best_auc_config.json\", 'w') as f:\n",
    "    json.dump({\n",
    "        'config': best_auc_config,\n",
    "        'objectives': {\n",
    "            'sensitivity': float(best_auc_objectives[0]),\n",
    "            'specificity': float(best_auc_objectives[1]),\n",
    "            'auc': float(best_auc_objectives[2]),\n",
    "            'model_size_M': float(best_auc_objectives[3])\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nBest configuration saved to {OUTPUT_DIR}/best_auc_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bElql9STYBHa"
   },
   "source": [
    "## 12. Select Configuration by Preference (Optional)\n",
    "\n",
    "Choose a configuration based on your priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihcxfTJ7YBHa"
   },
   "outputs": [],
   "source": [
    "# Find different optimal solutions\n",
    "best_sensitivity_idx = np.argmax(pareto_F[:, 0])\n",
    "best_specificity_idx = np.argmax(pareto_F[:, 1])\n",
    "smallest_model_idx = np.argmin(pareto_F[:, 3])\n",
    "\n",
    "print(\"Different Optimization Preferences:\\n\")\n",
    "\n",
    "print(f\"1. Best Sensitivity: {pareto_F[best_sensitivity_idx, 0]:.4f}\")\n",
    "print(f\"   AUC: {pareto_F[best_sensitivity_idx, 2]:.4f}, Size: {pareto_F[best_sensitivity_idx, 3]:.2f}M\\n\")\n",
    "\n",
    "print(f\"2. Best Specificity: {pareto_F[best_specificity_idx, 1]:.4f}\")\n",
    "print(f\"   AUC: {pareto_F[best_specificity_idx, 2]:.4f}, Size: {pareto_F[best_specificity_idx, 3]:.2f}M\\n\")\n",
    "\n",
    "print(f\"3. Best AUC: {pareto_F[best_auc_idx, 2]:.4f}\")\n",
    "print(f\"   Sens: {pareto_F[best_auc_idx, 0]:.4f}, Spec: {pareto_F[best_auc_idx, 1]:.4f}\\n\")\n",
    "\n",
    "print(f\"4. Smallest Model: {pareto_F[smallest_model_idx, 3]:.2f}M\")\n",
    "print(f\"   AUC: {pareto_F[smallest_model_idx, 2]:.4f}, Sens: {pareto_F[smallest_model_idx, 0]:.4f}, Spec: {pareto_F[smallest_model_idx, 1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lW9imMAYBHa"
   },
   "source": [
    "## 13. Results Summary\n",
    "\n",
    "All results have been saved to your Google Drive:\n",
    "- Pareto-optimal configurations\n",
    "- Optimization history\n",
    "- Visualizations\n",
    "- Best configuration JSON\n",
    "\n",
    "You can now:\n",
    "1. Download the results from Google Drive\n",
    "2. Use the best configuration to train a final model\n",
    "3. Deploy the model for inference\n",
    "4. Run additional experiments with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Example: Run optimization with 3 different seeds\n",
    "# Uncomment and run this cell for multiple experiments\n",
    "\n",
    "# seeds = [42, 123, 456]\n",
    "# all_results = {}\n",
    "\n",
    "# for seed in seeds:\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(f\"Running experiment with seed={seed}\")\n",
    "#     print(f\"{'='*70}\\n\")\n",
    "\n",
    "#     output_dir_seed = f\"{OUTPUT_DIR}/seed_{seed}\"\n",
    "\n",
    "#     results = run_optimization(\n",
    "#         hp_space=config.hyperparameter_space,\n",
    "#         nsga_config=config.nsga3,\n",
    "#         eval_function=eval_function,\n",
    "#         output_dir=output_dir_seed,\n",
    "#         seed=seed\n",
    "#     )\n",
    "\n",
    "#     all_results[seed] = results\n",
    "#     print(f\"\\nSeed {seed} completed. Found {len(results['pareto_configs'])} Pareto solutions.\")\n",
    "\n",
    "# # Compare results across seeds\n",
    "# print(f\"\\n{'='*70}\")\n",
    "# print(\"SUMMARY ACROSS ALL SEEDS\")\n",
    "# print(f\"{'='*70}\\n\")\n",
    "\n",
    "# for seed, results in all_results.items():\n",
    "#     pareto_F = np.array(results['pareto_F'])\n",
    "#     print(f\"Seed {seed}:\")\n",
    "#     print(f\"  Pareto solutions: {len(results['pareto_configs'])}\")\n",
    "#     print(f\"  Best AUC: {pareto_F[:, 2].max():.4f}\")\n",
    "#     print(f\"  Best Sensitivity: {pareto_F[:, 0].max():.4f}\")\n",
    "#     print(f\"  Best Specificity: {pareto_F[:, 1].max():.4f}\\n\")"
   ],
   "metadata": {
    "id": "F1gW8dPXYBHa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 14. Running Multiple Experiments with Different Seeds (Optional)\n",
    "\n",
    "For robust research results, run the optimization multiple times with different random seeds and compare the Pareto fronts."
   ],
   "metadata": {
    "id": "rQJ8c1zbYBHb"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}